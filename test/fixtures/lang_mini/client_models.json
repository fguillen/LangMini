{
  "data": [
    {
      "id": "google/gemini-flash-1.5-8b",
      "name": "Google: Gemini 1.5 Flash-8B",
      "created": 1727913600,
      "description": "Gemini 1.5 Flash-8B is optimized for speed and efficiency, offering enhanced performance in small prompt tasks like chat, transcription, and translation. With reduced latency, it is highly effective for real-time and large-scale operations. This model focuses on cost-effective solutions while maintaining high-quality results.\n\n[Click here to learn more about this model](https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/).\n\nUsage of Gemini is subject to Google's [Gemini Terms of Use](https://ai.google.dev/terms).",
      "context_length": 1000000,
      "architecture": {
        "modality": "text+image->text",
        "tokenizer": "Gemini",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000000375",
        "completion": "0.00000015",
        "image": "0",
        "request": "0"
      },
      "top_provider": {
        "context_length": 1000000,
        "max_completion_tokens": 8192,
        "is_moderated": false
      },
      "per_request_limits": {
        "prompt_tokens": "446832335",
        "completion_tokens": "111708083"
      }
    },
    {
      "id": "liquid/lfm-40b",
      "name": "Liquid: LFM 40B MoE",
      "created": 1727654400,
      "description": "Liquid's 40.3B Mixture of Experts (MoE) model. Liquid Foundation Models (LFMs) are large neural networks built with computational units rooted in dynamic systems.\n\nLFMs are general-purpose AI models that can be used to model any kind of sequential data, including video, audio, text, time series, and signals.\n\nSee the [launch announcement](https://www.liquid.ai/liquid-foundation-models) for benchmarks and more info.",
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "tokenizer": "Other",
        "instruct_type": "vicuna"
      },
      "pricing": {
        "prompt": "0",
        "completion": "0",
        "image": "0",
        "request": "0"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "per_request_limits": {
        "prompt_tokens": "Infinity",
        "completion_tokens": "Infinity"
      }
    },
    {
      "id": "liquid/lfm-40b:free",
      "name": "Liquid: LFM 40B MoE (free)",
      "created": 1727654400,
      "description": "Liquid's 40.3B Mixture of Experts (MoE) model. Liquid Foundation Models (LFMs) are large neural networks built with computational units rooted in dynamic systems.\n\nLFMs are general-purpose AI models that can be used to model any kind of sequential data, including video, audio, text, time series, and signals.\n\nSee the [launch announcement](https://www.liquid.ai/liquid-foundation-models) for benchmarks and more info.\n\n_These are free, rate-limited endpoints for [LFM 40B MoE](/liquid/lfm-40b). Outputs may be cached. Read about rate limits [here](/docs/limits)._",
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "tokenizer": "Other",
        "instruct_type": "vicuna"
      },
      "pricing": {
        "prompt": "0",
        "completion": "0",
        "image": "0",
        "request": "0"
      },
      "top_provider": {
        "context_length": 8192,
        "max_completion_tokens": 4096,
        "is_moderated": false
      },
      "per_request_limits": {
        "prompt_tokens": "Infinity",
        "completion_tokens": "Infinity"
      }
    },
    {
      "id": "thedrummer/rocinante-12b",
      "name": "Rocinante 12B",
      "created": 1727654400,
      "description": "Rocinante 12B is designed for engaging storytelling and rich prose.\n\nEarly testers have reported:\n- Expanded vocabulary with unique and expressive word choices\n- Enhanced creativity for vivid narratives\n- Adventure-filled and captivating stories",
      "context_length": 32768,
      "architecture": {
        "modality": "text->text",
        "tokenizer": "Qwen",
        "instruct_type": "chatml"
      },
      "pricing": {
        "prompt": "0.00000025",
        "completion": "0.0000005",
        "image": "0",
        "request": "0"
      },
      "top_provider": {
        "context_length": 32768,
        "max_completion_tokens": null,
        "is_moderated": false
      },
      "per_request_limits": {
        "prompt_tokens": "67024850",
        "completion_tokens": "33512425"
      }
    }
  ]
}
